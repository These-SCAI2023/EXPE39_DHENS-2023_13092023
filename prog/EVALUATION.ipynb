{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INtersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lg\n",
      "md\n",
      "sm\n",
      "lg\n",
      "md\n",
      "sm\n",
      "['lg', 'md', 'sm', 'lg', 'md', 'sm']\n",
      "['lg', 'md', 'sm', 'lg', 'md', 'sm']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2\n",
    "\n",
    "import glob\n",
    "\n",
    "def lire_fichier (chemin):\n",
    "    with open(chemin) as json_data: \n",
    "        dist =json.load(json_data)\n",
    "        \n",
    "        return dist\n",
    "    \n",
    "def nom_repertoire(chemin):\n",
    "    for mot in glob.glob(chemin): \n",
    "        noms_rep = re.split(\"/\", chemin)\n",
    "        noms_repo = re.split(\"_\",noms_rep[5])\n",
    "        noms_repo = re.split(\"_\",noms_repo[-1])\n",
    "        noms_repo =\"\".join(noms_repo)\n",
    "#        print(\"NOM FICHIER\",noms_fichiers)\n",
    "\n",
    "        return noms_repo\n",
    "\n",
    "def nom_mod(path):\n",
    "    for mot in glob.glob(path): \n",
    "        noms_mod = re.split(\"/\", path)\n",
    "        noms_mods = re.split(\"_\",noms_mod[6])\n",
    "        nm = re.split(\"_\",noms_mods[-2])\n",
    "        nmod =\"\".join(nm)\n",
    "        return nmod\n",
    "    \n",
    "\n",
    "def diagramme_venn(liste_en_pp, liste_en_ocr):\n",
    "    venn2([set(liste_en_pp), set(liste_en_ocr)],set_labels = ('En PP', 'EN OCR'))\n",
    "    \n",
    "    \n",
    "     \n",
    "def stocker(nom_fichier):\n",
    "    plt.savefig(nom_fichier)\n",
    "    plt.clf()\n",
    "    \n",
    "    return nom_fichier\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "path_corpora = \"./corpora/corpus_eval/*/*/*\"\n",
    "# dans \"corpora\" un subcorpus = toutes les versions 'un texte'\n",
    "\n",
    "liste_EN_ocr=[]\n",
    "liste_EN_pp=[]\n",
    "#for subcorpus in sorted(glob.glob(\"%s/*\"%path_corpora)):\n",
    "for subcorpus in sorted(glob.glob(path_corpora)):\n",
    "#    print(subcorpus)\n",
    "    for path in sorted(glob.glob(\"%s/*.json\"%subcorpus)):\n",
    "#        print(\"subsubcorpus\",path )\n",
    "    \n",
    "        texte = lire_fichier(path)\n",
    "    #    print(\"************\",subcorpus)\n",
    "    #    print(texte)\n",
    "        nomrep=nom_repertoire(path)\n",
    "    #    print(nomrep)\n",
    "        \n",
    "        if nomrep == \"PP\" :        \n",
    "            liste_EN_pp.append(path)\n",
    "    #        liste_texte_pp.append(subcorpus)\n",
    "            liste_EN_pp.append(texte)\n",
    "              \n",
    "        elif nomrep == \"MOD\":\n",
    "            liste_EN_ocr.append(path)\n",
    "    #         liste_texte_ocr.append(subcorpus)\n",
    "            liste_EN_ocr.append(texte)\n",
    "    \n",
    "    \n",
    "liste_ocr_verif=[] \n",
    "liste_pp_verif=[] \n",
    "i=0      \n",
    "while i <len(liste_EN_ocr) :\n",
    "    nom_mod_ocr=nom_mod(liste_EN_ocr[i])\n",
    "    nom_mod_pp=nom_mod(liste_EN_pp[i])\n",
    "    print(nom_mod_ocr)\n",
    "    liste_ocr_verif.append(nom_mod_ocr)\n",
    "    liste_pp_verif.append(nom_mod_pp)\n",
    "    i=i+2\n",
    "print(liste_ocr_verif)\n",
    "print(liste_pp_verif)\n",
    "\n",
    "result=True\n",
    "for j in range(0,len(liste_ocr_verif)):\n",
    "    if liste_ocr_verif[j]!=liste_pp_verif[j]:\n",
    "        result = False\n",
    "k=0\n",
    "if result != False:\n",
    "    while k<len(liste_EN_pp) :\n",
    "        \n",
    "        diagramme_venn(liste_EN_pp[k+1],liste_EN_ocr[k+1])\n",
    "        stocker(\"%s_intersection.png\"%liste_EN_ocr[k])\n",
    "        k=k+2\n",
    "       \n",
    "    \n",
    "else:\n",
    "    print(\"NOT OK\")\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "          \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AIMARD', 'les-trappeurs', 'PP', 'txt']\n",
      "['AIMARD', 'les-trappeurs', 'Kraken-base', 'txt']\n",
      "txt PP\n",
      "txt Kraken-base\n",
      "['AIMARD', 'les-trappeurs', 'PP', 'txt', 'md', 'spacy', 'json']\n",
      "['AIMARD', 'les-trappeurs', 'PP', 'txt', 'sm', 'spacy', 'json']\n",
      "['AIMARD', 'les-trappeurs', 'PP', 'txt', 'lg', 'spacy', 'json']\n",
      "['AIMARD', 'les-trappeurs', 'Kraken-base', 'txt', 'sm', 'spacy', 'json']\n",
      "['AIMARD', 'les-trappeurs', 'Kraken-base', 'txt', 'md', 'spacy', 'json']\n",
      "['AIMARD', 'les-trappeurs', 'Kraken-base', 'txt', 'lg', 'spacy', 'json']\n",
      "json md\n",
      "json sm\n",
      "json lg\n",
      "json sm\n",
      "json md\n",
      "json lg\n",
      "./corpora/corpus_eval/AIMARD_TRAPPEURS/AIMARD-TRAPPEURS_kraken-base_les-trappeurs_distances.json\n",
      "['AIMARD', 'les-trappeurs', 'PP', 'txt']\n",
      "['AIMARD', 'les-trappeurs', 'TesseractFra-PNG', 'txt']\n",
      "txt PP\n",
      "txt TesseractFra-PNG\n",
      "['AIMARD', 'les-trappeurs', 'PP', 'txt', 'md', 'spacy', 'json']\n",
      "['AIMARD', 'les-trappeurs', 'PP', 'txt', 'sm', 'spacy', 'json']\n",
      "['AIMARD', 'les-trappeurs', 'PP', 'txt', 'lg', 'spacy', 'json']\n",
      "['AIMARD', 'les-trappeurs', 'TesseractFra-PNG', 'txt', 'lg', 'spacy', 'json']\n",
      "['AIMARD', 'les-trappeurs', 'TesseractFra-PNG', 'txt', 'md', 'spacy', 'json']\n",
      "['AIMARD', 'les-trappeurs', 'TesseractFra-PNG', 'txt', 'sm', 'spacy', 'json']\n",
      "json md\n",
      "json sm\n",
      "json lg\n",
      "json lg\n",
      "json md\n",
      "json sm\n",
      "./corpora/corpus_eval/AIMARD_TRAPPEURS/AIMARD-TRAPPEURS_TesseractFra-PNG_les-trappeurs_distances.json\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import glob\n",
    "import spacy\n",
    "import json\n",
    "import sklearn\n",
    "import os\n",
    "\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "def lire_fichier_txt (chemin):\n",
    "    f = open(chemin , encoding = 'utfâˆ’8')\n",
    "    chaine = f.read ()\n",
    "    f.close ()\n",
    "    return chaine\n",
    "\n",
    "def liste_resultats(texte, nlp=spacy.load(\"fr_core_news_sm\")):\n",
    "    doc = nlp(texte)\n",
    "    list_resultats =[]\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_==\"LOC\":\n",
    "            list_resultats.append(ent.text)\n",
    "    return (list_resultats)\n",
    "\n",
    "\n",
    "def stocker( chemin, contenu):\n",
    "\n",
    "    w =open(chemin, \"w\")\n",
    "    w.write(json.dumps(contenu , indent = 2))\n",
    "    w.close()\n",
    "    print(chemin)\n",
    "    \n",
    "\n",
    "\n",
    "def get_distances(texte1, texte2, N=1, liste_name =[\"jaccard\", \"braycurtis\",\"dice\", \"cosinus\"] ):\n",
    "    dico = {}\n",
    "    for metric_name in liste_name :\n",
    "        dico[metric_name] = []\n",
    "        liste_resultat_dist2 = []\n",
    "        for n_max in range(1, N+1):###range([min, default = 0], max, [step, default = 1]) \n",
    "            V = CountVectorizer(ngram_range=(1,n_max ), analyzer='char') \n",
    "            X = V.fit_transform([texte1, texte2]).toarray()\n",
    "            if metric_name!= \"cosinus\" :  \n",
    "                dist = DistanceMetric.get_metric(metric_name)     \n",
    "                distance_tab1=dist.pairwise(X)\n",
    "                liste_resultat_dist2.append(distance_tab1[0][1])\n",
    "            else: \n",
    "                distance_tab1=sklearn.metrics.pairwise.cosine_distances(X) \n",
    "                liste_resultat_dist2.append(distance_tab1[0][1])\n",
    "            dico[metric_name] = liste_resultat_dist2\n",
    "    return dico\n",
    "\n",
    "\n",
    "## MAIN\n",
    "\n",
    "for subcorpus in glob.glob('./corpora/corpus_eval/*/*'):\n",
    "    outputs = glob.glob(f\"{subcorpus}/*/*\")\n",
    "    dico_out = {}\n",
    "    dist_txt = {}\n",
    "    for file_type in [\"txt\", \"json\"]:\n",
    "        chemins = [x for x in outputs if len(re.findall(f\"{file_type}$\",x))>0]\n",
    "        liste_compare = []\n",
    "        for path_file in chemins:\n",
    "            filename = re.split(\"/\", path_file)[-1]\n",
    "            elems = re.split(\"_|\\\\.\", filename)\n",
    "            print(elems)\n",
    "            auteur,titre, version, modele = elems[0], elems[1],elems[2], elems[-3]\n",
    "            if file_type ==\"txt\":\n",
    "                liste_compare.append([version, lire_fichier_txt(path_file)])\n",
    "            else:\n",
    "                liste_compare.append([modele, lire_fichier_txt(path_file)])\n",
    "        for c in liste_compare:\n",
    "            print(file_type, c[0])\n",
    "        dico_out[file_type] = {}\n",
    "        for ID1 in range(len(liste_compare)):\n",
    "            version1 = liste_compare[ID1][0]\n",
    "            for ID2 in range(ID1+1, len(liste_compare)):\n",
    "                version2 = liste_compare[ID2][0]\n",
    "                dico_dist = get_distances(liste_compare[ID1][1], liste_compare[ID2][1], N=5)\n",
    "                paire = \"%s--%s\"%(version1, version2)\n",
    "                dico_out[file_type][paire] = dico_dist\n",
    "    \n",
    "    \n",
    "       \n",
    "    stocker(\"%s_%s_distances.json\"%(subcorpus,titre), dico_out)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
